#Upcales reponse by unit and river style to a network

#Natalie Kramer (n.kramer.anderson@gmail.com)
#Last Updated Aug 13 2019

#Documentation available on 
#https://natalie-kramer.github.io/GeomorphicUpscale/

# To Do ------------------------------------------------------------
#eliminate species and model from directory structure and instead include as field in output table?  Maybe append to this table
#when run for different species or just run for all species and model types on the fly-- not make a user variable...?

#get rid of condition character warnings during join in upscale part.

#upscale geomorphic variables (maybe in different script?) ex.# units to reach upscale.  Also Percent of each unit type.

#Need to think about how we are summarizing predicted fish and getting sd dev. check sd calculations for correctness.
#the right now there is none because it is the total fish / tota area of a certain unit....
#perhaps we need to be summarizing by each site and then taking the average fish per unit type across sites so that 
#the standard deviation is reflective of the variation across sites rather than across units (which I am not really using...)
#so basically I would need to sum across individual units in the response script prior to summarizing the data. Then in this script, I would just use the avg rather than the tot.

# Dependencies ------------------------------------------------------------

require(ggplot2)
require(dplyr)
require(tidyr)

source(paste(GUPdir, "\\scripts\\plot.colors.R", sep=""))
source(paste(GUPdir, "\\scripts\\functions.R", sep=""))

###user variables defined in UpscaleWrapper.R###
PROJdir=PROJdir  #directory path to local project
GUPdir=GUPdir   #directory path to Github repo
selections=selections #directory path to input selections file generated by RSselection.R
gu.type=gu.type      #Options: UnitForm, GU #UnitShape not available at this time since I don't have maps of these in the database
RSlevels=RSlevels #optional vector argument to set RS factor order in graphs and displays, leave as  NA if alphabetical is desired
plottype=plottype   #Options: .tiff, .png, .pdf, "none"
myscales=myscales #Options: fixed or free x/y axis scales for tiled plot output
model=model        	#Options: nrei, fuzzy, NA #I could hardcode this for now..., one less variable.
species=species        #Options: steelhead, chinook, NA  #I could hardcode this for now..., one less variable.

network=network
braid.index=braid.index
responsepool=responsepool #Options: "byAll", "byRS", "byRScond"
segIDcol=segIDcol
lengthcol=lengthcol
widthcol=widthcol
condcols=condcols
areacols=areacols


# set up data refs and output file structure  ------------------------------------------------------------------------
print("setting up data refs and output file structure...")

#specify subdirectory paths to input files.
response.subdir=c("response" , species, model, "by.unit", gu.type, responsepool)
gu.subdir=c( "assemblage" , gu.type, "by.unit")

#Create subdirectories based on user variable choices
outsubdir=c("Outputs","upscale", response.subdir)
create.subdirs(PROJdir, outsubdir)

#Create output subdirectories for upscaling of assemblage stats- I'm not doing this yet-- maybe in new script?
#create.subdirs(PROJdir, c("Outputs", "upscale",  "assemblage", gu.type))

#specify OUTput directory as variable
OUTdir=paste(PROJdir, paste(outsubdir, collapse="\\"), sep="\\")

#delete any existing files in Output from previous runs
unlink(paste(OUTdir,"\\*", sep=""), recursive=T)

#specify GUT output layer to draw data from based on gu.type
if(gu.type=="GU"){layer="Tier3_InChannel"}
if(gu.type=="UnitForm" | gu.type=="UnitShape"){layer="Tier2_InChannel_Transition" }


# Reads in and restructures data----------------------------------------------------
print("readin in data...")

#Read in response variable by responsepool variable
#We should make more universal to upscale other responses besides pred.fish. For now, 
#I am hardcoding this.

#reads in response stats
response=read.csv(paste(PROJdir, "Outputs",paste(response.subdir, collapse="\\"), 
                         "stats.csv", sep="\\"))

#this can be re-coded later to allow for upscaling of different ROI using alternate methods
response.area=response%>%filter(variable=="area", ROI=="hydro")%>%
  select(RS, Condition, unit.type, tot)%>%
  rename(hydro.area.m2=tot)

#filters out just data on number of fish
#this can be re-coded later to allow for upscaling of different variables
response.pred.fish=response%>%filter(variable=="pred.fish", ROI=="hydro")%>%
  select(RS, Condition, unit.type, tot)%>%
  rename(pred.fish=tot) #changed to avg if I decided to sum up over units then average by sites in the other script
#this would give me a avg number of fish per unit type with a standard deviation.  Right now, I 
#don't have a st. deviation on number of fish

#Read in estimates of Assemblages and re-arrange. 
#FOr now hardcoding for byRScond.  Could make the poolbby variable in the future.
#Need condition variations anyway to run scenarios in upscale.

#read in estimated assemblages for each RS and Condition
assemblage=read.csv(paste(PROJdir, "Outputs",paste(gu.subdir, collapse="\\"),"byRScond" , "assemblage.csv", sep="\\"))%>%
  select(-SUM)%>%rename('Mound Transition'=Mound.Transition, 'Bowl Transition'=Bowl.Transition)

#renormalized assemblage ratios converted to long format

#reads in gu stats.csv
gu.stats=read.csv(paste(PROJdir, "Outputs",paste(gu.subdir, collapse="\\"),"byRScond" , "stats.csv", sep="\\"))

#selects just the total area for each RS, condition and unit.type
gu.bf.area=gu.stats%>%filter(variable=="area.sum", ROI=="bankfull")%>%
  select(RS, Condition, unit.type, tot)%>%
  rename(area.m2=tot)

#selects the standard deviation of assemblage ratios for each RS and condition
gu.sd.ratio.bf.area=gu.stats%>%filter(variable=="area.ratio", ROI=="bankfull")%>%
  select(RS, Condition, unit.type, sd)%>%
  rename(sd.ratio.area=sd)

levels=levels(gu.stats$unit.type)
gu.ratio.bf.area=assemblage%>%gather(key="unit.type", value="ratio.area",
                                     (length(names(assemblage))-length(levels)+1):length(names(assemblage)))%>%
  select(RS, Condition, unit.type, ratio.area)
gu.ratio.bf.area$unit.type=as.factor(gu.ratio.bf.area$unit.type)


# assembling upscale data----------------------------------------------------
#Combining response and assemblage data
print("assembling upscale data")



#conditionals for dealing with different responsepools
if(responsepool=="byRScond"){joinby=c("RS", "Condition", "unit.type")}
if(responsepool=="byRS"){joinby=c("RS", "unit.type")}

joinbyRSCond=c("RS", "Condition", "unit.type")

#computes fish density for upscale. Can be appended to later to accomodate density within hydro or wetted.
#but, I need the assemblages within the wetted extent in order to do this type of upscale.
bf.density=gu.bf.area%>%
  #left_join(response.area, by=joinbyRSCond)%>%
  left_join(gu.ratio.bf.area, joinbyRSCond)%>%
  left_join(gu.sd.ratio.bf.area, joinbyRSCond)%>%
  left_join(response.pred.fish, by=joinby)%>%
  #left_join(response.sd.pred.fish,by=joinbyRS) Not needed unless I do my summary of response differently.
  mutate(sd.pred.fish=NA)%>%
  mutate(fish.density=pred.fish/area.m2, sd.fish.density=sd.pred.fish/area.m2)%>% #could calculate also using perc habitat area, gets around the bankfull issue.
  select(RS, Condition, unit.type, ratio.area, sd.ratio.area,fish.density, sd.fish.density)%>%
  mutate(ROI="bankfull")


#If adding more variables for upscale (ex. Model values, perc habitat, etc), could be handy to have in long (gathered) format instead.
upscale.response=bf.density

# Upscales response on the network for different scenarios ------------------------------

print("upscaling response on the network for different condition senarios")

#Finds position of columns related to defined header in network file

condcols.n=match(condcols,colnames(network))
RScol.n=which(colnames(network)=="RS")
segIDcol.n=which(colnames(network)==segIDcol)
lengthcol.n=which(colnames(network)==lengthcol)
widthcol.n=which(colnames(network)==widthcol)


#This is the part that does the upscaling on the network for each cond col scenario (the for loop)

#fix character warnings
for(i in 1:length(condcols.n)){ #maybe this can be changed to an lapply or something.
  
upscale=network[,c(segIDcol.n,RScol.n, condcols.n[i], lengthcol.n, widthcol.n)]
names(upscale)=c(names(network)[segIDcol.n],"RS", "Condition","reach.length", "reach.width")

#Estimate area based on condition and braid.index or specify user supplied areas
Estimate.Area=function(data, condcol.n, RScol.n, segIDcol.n, lengthcol.n, widthcol.n){
  length=data[,lengthcol.n]
  width=data[, widthcol.n]
  C=braid.index%>%select(RS, Condition, C)%>%
    right_join(data, by = c("RS", "Condition"))%>%select(C)
  area=length*width*as.data.frame(C)[,1]
  return(area)
}

if(is.na(areacols)){
 area=Estimate.Area(data=upscale, condcol.n=3, RScol.n=2, segIDcol.n=1, lengthcol.n=4, widthcol.n=5)
 area.method="estimated"
}else{
  areacol.n=match(areacols[i],colnames(network))
  area=network[,areacol.n]
  area.method="given"
}
  
#set upscale data table for condition scenario to include area 
  upscale = upscale%>%mutate(reach.area=area, area.method=area.method)%>%mutate(reach.braid=reach.area/reach.length/reach.width)
 # head(upscale)

#combine upscale network segments with response- tied to RS and condition specified on network
upscale1=upscale%>%
    full_join(upscale.response%>%filter(ROI=="bankfull"), by=c("RS", "Condition"))%>%
    filter(!is.na(.[,1])) #removes any rows with NA for segID left over from join

#Upscale Math #if using more variables better in long format and then adjust this to be more generic, selecting by upscale variable of interest
upscale2=upscale1%>%
  mutate(value=ratio.area*reach.area*fish.density)%>% #compute estimated fish per unit type per reach
  mutate(value.sd=abs(value)*sqrt((sd.ratio.area/ratio.area)^2))%>% #compute estimated sd of fish per unit type per reach type
  #mutate(value.sd=abs(value)*sqrt((sd.ratio.area/ratio.area)^2 + (sd.fish.density/fish.density)^2))%>% #change to this once I get the sd of fish denisty included.
  group_by(.[,1], RS, Condition, reach.length, reach.width, reach.area, area.method, reach.braid)%>% #groups by segment id, then RS then Condition
  summarize(value=sum(value, na.rm=T), value.sd=sqrt(sum(value.sd^2, na.rm=T)))%>%
  mutate(variable="pred.fish")


upscale2$Scenario= names(network)[condcols.n[i]] #add field that specifies which condition scenario was used.

#math for SE rather than standard deviation
#varSE=abs(var)*sqrt(((sd/sqrt(n))/PercGU)^2+((sd.r/sqrt(n.r))/bfdensity)^2) #SE includes n
#varSD=abs(var)*sqrt((sd/PercGU)^2+(sd.bfdensity/bfdensity)^2))
 
  if(i==1){reachupscale=upscale2}else{reachupscale=rbind(reachupscale,upscale2)}
} #this is the end of the for loop.




reachupscale$species=species
reachupscale$model=model
reachupscale$responsepool=responsepool
reachupscale$gu.type=gu.type

#group results by Scenario and RS and Condition
a=reachupscale%>%
  group_by(Scenario, RS, Condition, area.method, model, species, variable, responsepool, gu.type )
#group results by Scenario and  RS
b=reachupscale%>%
  group_by(Scenario, RS, area.method, model, species, variable, responsepool , gu.type)
#group results by only Scenario 
c=reachupscale%>%
  group_by(Scenario, area.method, model, species,  variable, responsepool, gu.type )  
  
#make basin summaries
reachsummary=function(groupeddata){
  groupeddata%>%summarize(value=sum(value,na.rm=T), 
                          value.sd= sqrt(sum(value.sd^2, na.rm=T)),
                          tot.area=sum(area,na.rm=T),
                          tot.length=sum(reach.length, na.rm=T),
                          mean.width=mean(reach.width, na.rm=T),
                          sd.width=sd(reach.width, na.rm=T),
                          mean.braid=mean(reach.braid, na.rm=T),
                          sd.braid=sd(reach.width, na.rm=T),
  )
}

basinupscale_RScond=reachsummary(a)
basinupscale_RS=reachsummary(b)
basinupscale=reachsummary(c)

#write output to file
write.csv(reachupscale, paste(OUTdir, "\\" ,"byreach.csv", sep=""), row.names=F)
write.csv(basinupscale, paste(OUTdir, "\\", "bybasin.csv", sep=""), row.names=F)
write.csv(basinupscale_RS, paste(OUTdir, "\\", "bybasin_RS.csv", sep=""), row.names=F)
write.csv(basinupscale_RScond, paste(OUTdir, "\\", "bybasin_RScond.csv", sep=""), row.names=F)


print(paste("files written to: ", OUTdir))

# cleaning up ----------------------------------------------

print("erasing temporary variables")


keepvars=c("selections", "PROJdir","GUPdir", "plottype", "myscales" , "RSlevels", "gu.type", 
           "species", "model",  "network", "braid.index",
            "responsepool", "segIDcol", "lengthcol" , "widthcol" , "condcols", "areacols")

rm(list=ls()[-match(x = keepvars, table = ls())])

print("done")


#Plots need to be re-done so for now I have commented out old work
# if(makeplot==Hahahaha){
#   library(ggplot2)
# 
#   
#   if(validateselection==F){
#   #Stacked barplot
#     
#  plotdata=merge(network, as.data.frame(reachupscale), by=segIDcol)
#  distcol.n=match(distcol,colnames(plotdata))
#   names(plotdata)[distcol.n]="StreamL"
#   
#   plotdata=plotdata%>%
#     group_by(Scenario,RScond.y)%>%
#     summarize(var=sum(var),Area=sum(Area), StreamL=sum(StreamL))%>%
#     extract(RScond.y, into = c("RS"), "(.[:upper:]*)", remove=F)%>%
#     extract(RScond.y, into = c("Condition"), "([:lower:].*)", remove=F)
#   
# 
#   
#   mycolors=c(good="forest green", mod="gold", poor="firebrick1", intact="light blue")
#   
#   myplot= ggplot()+geom_col(data=plotdata, aes(x=Scenario, y=var/StreamL , fill=Condition))+
#     scale_fill_manual(values = mycolors)+
#     facet_grid( ~ RS) +
#     facet_wrap( ~ RS, scales='fixed')+
#     ylab(upscalevar)+
#     xlab("")+
#     theme(axis.text.x=element_text(angle=45,hjust=1))
#   myplot
#   
#   #myplot+geom_col(data=plotdata, aes(x=Scenario, y=var/Length*100, fill=Condition))+
#   #ylab(paste(upscalevar, " per 100 m",sep=""))
#   
#   
#   if(plottype==".pdf"){
#     ggsave(paste(OUTfolder, "\\", "ScenariocomparisonbyRS.pdf", sep=""), plot=myplot, width = 7, height = 5 )}
#   
#   if(plottype==".png"){
#     ggsave(paste(OUTfolder, "\\", "ScenariocomparisonbyRS.png", sep=""), plot=myplot, width = 7, height = 5)}
#   #png(paste(OUTdir,"\\", layer, "_assemblage.png", sep=""))}
#   
#   if(plottype==".tiff"){
#     ggsave(paste(OUTfolder, "\\", "ScenariocomparisonbyRS.tiff", sep=""), plot=myplot, width = 7, height = 5)}
#   }
#     
#  if(validateselection==T){
#    
#   data$visit=as.character(data$visit)
#   
#    joindata=reachupscale%>%
#      extract(RScond, into = c("RS"), "(.[:upper:]*)", remove=F)%>%
#      extract(RScond, into = c("Condition"), "([:lower:].*)", remove=F)%>%
#      left_join(data, by=c("visit"))
#    names(joindata)=gsub(".x", "", names(joindata), fixed=T)
#    joindata=joindata[,-grep("[.]y", names(joindata))]
#    
#   # write.csv(joindata, paste(OUTfolder, "\\" ,"Selection_validationjoin.csv", sep=""), row.names=F)
#    
#    joindata1=na.omit(joindata)
#    if(upscalevar=="Capacity"){
#      X=as.numeric(joindata1$Capacity_M)
#    }
#    if(upscalevar=="ModelVal"){
#      X=as.numeric(joindata1$MedModelVal_M)
#    }
#    Y=as.numeric(joindata1$var)
# 
#    mycolors=c(poor="red", mod="yellow", good="green", intact="purple")
#    
#    
#    myplot= ggplot(data=joindata1)+
#      scale_colour_manual(values = mycolors)+
#      xlab(paste("directly modelled", upscalevar))+
#      ylab(paste("upscaled estimate of" , upscalevar))
# 
#    
#    validate=myplot+
#      geom_label(aes(x=X, y=var, label=visit),hjust=0, vjust=0, label.size=0.1, label.padding=unit(0.1, "lines"))+
#      geom_abline(intercept=0, slope=1, lty=1, lwd=1) +
#      geom_point(aes(x=X, y=var, col=Condition, shape=RS))
#    
#    
#    perAreavalidate=myplot+
#      geom_label(aes(x=X/WEArea, y=var/WEArea, label=visit),hjust=0, vjust=0, label.size=0.1, label.padding=unit(0.1, "lines"))+
#      geom_abline(intercept=0, slope=1, lty=1, lwd=1) +
#      geom_point(aes(x=X/WEArea, y=var/WEArea, col=Condition, shape=RS))+
#       xlab(paste("directly modelled" , responsevar, "in Wetted Extent"))+
#      ylab(paste("upscaled estimate", , responsevar, "in Wetted Extent"))
# 
#     perLengthvalidate=myplot+
#      geom_label(aes(x=X/Length, y=var/Length, label=visit),hjust=0, vjust=0, label.size=0.1, label.padding=unit(0.1, "lines"))+
#      geom_abline(intercept=0, slope=1, lty=1, lwd=1) +
#      geom_point(aes(x=X/Length, y=var/Length, col=Condition, shape=RS))+
#      xlab(paste("directly modelled ", responsevar, " per 100 m ",sep=""))+
#      ylab(paste("upscaled estimate of " ,responsevar, " per 100 m", sep=""))
#    
#    
# 
#    if(plottype==".pdf"){
#      ggsave(paste(OUTfolder, "\\", "SelectionCapacityvalidation.pdf", sep=""), plot=Capacityvalidate, width = 7, height = 5 )
#     ggsave(paste(OUTfolder, "\\", "SelectionCapacityperAreavalidation.pdf", sep=""), plot=CapacityperAreavalidate, width = 7, height = 5 )
#     ggsave(paste(OUTfolder, "\\", "SelectionCapacityperLengthvalidation.pdf", sep=""), plot=CapacityperLengthvalidate, width = 7, height = 5 )}
#    
#    if(plottype==".png"){
#      ggsave(paste(OUTfolder, "\\", "SelectionCapacityvalidation.png", sep=""), plot=Capacityvalidate, width = 7, height = 5)
#       ggsave(paste(OUTfolder, "\\", "SelectionCapacityperAreavalidation.png", sep=""), plot=CapacityperAreavalidate, width = 7, height = 5 )
#       ggsave(paste(OUTfolder, "\\", "SelectionCapacityperLengthvalidation.png", sep=""), plot=CapacityperLengthvalidate, width = 7, height = 5 )}
#    
#    if(plottype==".tiff"){
#      ggsave(paste(OUTfolder, "\\",  "SelectionCapacityvalidation.tiff", sep=""), plot=Capacityvalidate, width = 7, height = 5)
#     ggsave(paste(OUTfolder, "\\", "SelectionCapacityperAreavalidation.tiff", sep=""), plot=CapacityperAreavalidate, width = 7, height = 5 )
#     ggsave(paste(OUTfolder, "\\", "SelectionCapacityperLengthvalidation.tiff", sep=""), plot=CapacityperLengthvalidate, width = 7, height = 5 )}
#    
#    
#  }
#   

#  }

#PLOTS UP SCENARIO PLOTS
 
# percchnge=(reachupscale.r$capby100L-reachupscale$capby100L)/reachupscale$capby100L*100
# #percchngep=(reachupscale.r$cap.p.sd-reachupscale$cap.p.sd)/reachupscale$100L.p.sd*100
# #percchngem=(reachupscale.r$cap.m.sd-reachupscale$cap.m.sd)/reachupscale$cap.m.sd*100
# 
# chnge=cbind(reachupscale[,c(1,5,6,7)], percchnge)%>%
#   full_join(AGA.data, by="segmentID")
# 
# lowrecovery=which(chnge$RecPotent=="Low Recovery Potential")
# goodcurrent=which(chnge$Condition=="Good")
# chngesub=chnge[-c(lowrecovery, goodcurrent),]
# 
# #boxplot(chngesub$percchnge~chngesub$RScurrent)
# 
# chngesum=chngesub%>%
#   group_by(as.factor(RScurrent))%>%
#   summarize(avg=mean(percchnge, na.rm=T), n=length(na.omit(percchnge)))
# 
# par(mfrow=c(2,1),mar=c(5,7,2,2))
# barplot(height=chngesum[-c(1:3,6,12),]$avg, 
#         names.arg=as.character(as.data.frame(chngesum[-c(1:3,6,12),])[,1]), 
#         horiz=T, las=2, xlab="Average %Change in Juvenile Rearing Capacity from Current to Restored",
#         xlim=c(-10,40))
# 
# barplot(height=chngesum[-c(1:3,6,12),]$avg, 
#         names.arg=as.character(as.data.frame(chngesum[-c(1:3,6,12),])[,1]), 
#         horiz=T, las=2, xlab="Average %Change in Spawning Capacity from Current to Restored",
#         ,xlim=c(-10,40))




